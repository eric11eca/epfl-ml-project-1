{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = \"../data/train.csv\" # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2', '1', '1', ..., '1', '0', '0'], dtype='<U1')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(DATA_TRAIN_PATH, \"r\") as f:\n",
    "            title_list = f.readline().split(\",\")\n",
    "\n",
    "jet_num_col = title_list.index(\"PRI_jet_num\")\n",
    "\n",
    "category_tx = np.genfromtxt(\n",
    "    DATA_TRAIN_PATH, dtype=str, delimiter=\",\", skip_header=1, usecols=[jet_num_col])\n",
    "category_tx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, data_pth, data_type):\n",
    "        self.data_pth = f\"{data_pth}/{data_type}.csv\"\n",
    "        self.data_type = data_type\n",
    "\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.ids = []\n",
    "\n",
    "        self.col_names = self.read_col_names()\n",
    "        self.num_cols = len(self.col_names)\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Load the data from the csv file.\"\"\"\n",
    "\n",
    "        y, tX, ids = load_csv_data(self.data_pth)\n",
    "        self.ids = ids\n",
    "        self.labels = y\n",
    "        self.data = tX\n",
    "\n",
    "    def read_col_names(self):\n",
    "        \"\"\"Read the column names from the csv file.\"\"\"\n",
    "\n",
    "        with open(self.data_pth, \"r\") as f:\n",
    "            col_names = f.readline().strip().split(\",\")\n",
    "        return col_names\n",
    "    \n",
    "    def data_imputation(self, method=\"mean\"):\n",
    "        \"\"\"Impute the missing values in the data.\"\"\"\n",
    "\n",
    "        for col in range(self.num_cols):\n",
    "            col_data = self.data[:, col]\n",
    "            if method == \"mean\":\n",
    "                col_data[col_data == -999.0] = np.nanmean(col_data[col_data != -999.0])\n",
    "                col_data[np.isnan(col_data)] = np.nanmean(col_data)\n",
    "            elif method == \"median\":\n",
    "                col_data[col_data == -999.0] = np.nanmedian(col_data[col_data != -999.0])\n",
    "                col_data[np.isnan(col_data)] = np.nanmedian(col_data)\n",
    "            else:\n",
    "                col_data[col_data == -999.0] = 0.0\n",
    "                col_data[np.isnan(col_data)] = 0.0\n",
    "\n",
    "        if method == \"mean\":\n",
    "            self.data = self.mean_imputation()\n",
    "    \n",
    "    def data_normalization(self):\n",
    "        \"\"\"Normalize the data, zero-mean and standardization.\"\"\"\n",
    "\n",
    "        mean_data = np.mean(self.data, axis=0)\n",
    "        self.data = self.data - mean_data\n",
    "        std_data = std_data / np.std(self.data, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(\"../data\", \"train\")\n",
    "train_dataset.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_col = train_dataset.col_names.index(\"Id\")\n",
    "label_col = train_dataset.col_names.index(\"Prediction\")\n",
    "jet_num_col = train_dataset.col_names.index(\"PRI_jet_num\")\n",
    "special_col = [id_col, label_col, jet_num_col]\n",
    "float_col_ids = []\n",
    "float_col_names = []\n",
    "category_col_names = ['jetnum3', 'jetnum2', 'jetnum1', 'jetnum0']\n",
    "for idx in range(len(title_list)):\n",
    "    if idx not in special_col:\n",
    "        float_col_ids.append(idx)\n",
    "        float_col_names.append(title_list[idx])\n",
    "        full_col_names = ['x_bias'] + float_col_names + category_col_names\n",
    "len(full_col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"Normalize the dataset x.\"\"\"\n",
    "    mean_x = np.mean(x, axis=0)\n",
    "    std_x = np.std(x, axis=0)\n",
    "    x = (x - mean_x) / std_x\n",
    "    return x\n",
    "\n",
    "tX_norm = normalize(tX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = \"../data/test.csv\" # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.9.12 ('causal')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "470f44e489c3417f40e6fbafbb8f6893ee0c258fcccc4737e0ea9152abfd2d49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
